{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from model import (QuadraticDendriticNet, LinearNeuralNet, QuadraticNeuralNet)\n",
    "\n",
    "D = 28 * 28\n",
    "K = 10\n",
    "features = (D, 2048, K)\n",
    "num_tasks = 20\n",
    "num_epochs = 10\n",
    "batch_size = 6000\n",
    "learning_rate = 0.01\n",
    "\n",
    "def prepare_dataset():\n",
    "    train_loader, test_loader, prototype = {}, {}, {}\n",
    "\n",
    "    permute_idx = list(range(D))\n",
    "    for task in range(num_tasks):\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        # dataset before permute\n",
    "        train_set = torchvision.datasets.MNIST(\n",
    "            root='', train=True, download=True, transform=transform\n",
    "        )\n",
    "        test_set = torchvision.datasets.MNIST(\n",
    "            root='', train=False, download=True, transform=transform\n",
    "        )\n",
    "\n",
    "        # permute the dataset according to permute index\n",
    "        train_set.data = train_set.data.reshape(-1, D)[:, permute_idx]\n",
    "        test_set.data = test_set.data.reshape(-1, D)[:, permute_idx]\n",
    "\n",
    "        # Compute the context vector of current task\n",
    "        prototype[task] = torch.mean(Tensor.float(train_set.data), dim=0)\n",
    "\n",
    "        # Data loader\n",
    "        train_loader[task] = torch.utils.data.DataLoader(\n",
    "            dataset=train_set, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        test_loader[task] = torch.utils.data.DataLoader(\n",
    "            dataset=test_set, batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "        # shuffle the permutation index\n",
    "        permute_idx = torch.randperm(D).tolist()\n",
    "\n",
    "    return train_loader, test_loader, prototype\n",
    "\n",
    "def test_all_task(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        for task in range(num_tasks):\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader[task]:\n",
    "                images = images.reshape(-1, 28*28)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Task [{}/{}], Accuracy: {} %'\n",
    "                  .format(task+1, num_tasks, 100 * correct / total))\n",
    "\n",
    "train_loader, test_loader, context_vector = prepare_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def is_match(x, y, threshold=0.99):  # N_x * D, N_y * D\n",
    "    x_n, d = x.shape  # N_x, D\n",
    "    y_n, _ = y.shape  # N_y\n",
    "\n",
    "    mean_x = torch.mean(x, dim=0, keepdim=True)  # 1 * D\n",
    "    mean_y = torch.mean(y, dim=0, keepdim=True)  # 1 * D\n",
    "    mean_diff = mean_x - mean_y  # 1 * D\n",
    "    centered_x = x - mean_x  # N_x * D\n",
    "    centered_y = y - mean_y  # N_y * D\n",
    "\n",
    "    cov_x = torch.t(centered_x) @ centered_x  # D * D\n",
    "    cov_y = torch.t(centered_y) @ centered_y  # D * D\n",
    "    pooled_cov = ( cov_x + cov_y ) / ( x_n + y_n - 2 )  # D * D\n",
    "\n",
    "    t2 = mean_diff @ torch.pinverse(pooled_cov) @ torch.t(mean_diff)\n",
    "    t2 = (x_n * y_n * t2) / (x_n + y_n)\n",
    "    f = (t2 * (x_n + y_n - d - 1)) / (d * (x_n + y_n - 2))\n",
    "\n",
    "    return f <= threshold\n",
    "\n",
    "\n",
    "def cluster(x, y_t, p) -> int:  # N_x * D, T * N_y * D, T\n",
    "    for task in range(len(p)-1, -1, -1):\n",
    "        if is_match(x, y_t[task]):\n",
    "            y_t[task] = torch.cat((x, y_t[task]))  # (N_x + N_y) * D\n",
    "            p[task] = torch.mean(y_t[task], dim=0)\n",
    "            return task\n",
    "    y_t[len(p)] = x\n",
    "    p[len(p)] = torch.mean(y_t[len(p)], dim=0)\n",
    "    return len(p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task=1\n",
      "1\n",
      "task=2\n",
      "2\n",
      "task=3\n",
      "3\n",
      "task=4\n",
      "4\n",
      "task=5\n",
      "5\n",
      "task=6\n",
      "6\n",
      "task=7\n",
      "8\n",
      "task=8\n",
      "10\n",
      "task=9\n",
      "12\n",
      "task=10\n",
      "13\n",
      "task=11\n",
      "14\n",
      "task=12\n",
      "15\n",
      "task=13\n",
      "16\n",
      "task=14\n",
      "17\n",
      "task=15\n",
      "18\n",
      "task=16\n",
      "19\n",
      "task=17\n",
      "20\n",
      "task=18\n",
      "21\n",
      "task=19\n",
      "23\n",
      "task=20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "y_t = {}  # key: task, value: batch of the task, [D]\n",
    "p = {}  # key: task, value: prototype, [D]\n",
    "\n",
    "for task in range(num_tasks):\n",
    "    for step, (x, _) in enumerate(train_loader[task]):\n",
    "        cluster(x.reshape(-1, D), y_t, p)\n",
    "    print(\"task={}\".format(task+1))\n",
    "    print(len(p))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_set = []\n",
    "for task in range(num_tasks):\n",
    "    for step, (x, labels) in enumerate(train_loader[task]):\n",
    "        all_set.append((task, (x, labels)))\n",
    "random.shuffle(all_set)\n",
    "\n",
    "y_t = {}  # key: task, value: batch of the task, [D]\n",
    "p = {}  # key: task, value: prototype, [D]\n",
    "\n",
    "map = {}\n",
    "for task in range(num_tasks): map[task] = []\n",
    "\n",
    "already = set()\n",
    "for task_idx, (x, _) in all_set:\n",
    "    predict_task = cluster(x.reshape(-1, D), y_t, p)\n",
    "    already.add(task_idx)\n",
    "    print('{} : {}'.format(len(p), len(already)))\n",
    "\n",
    "    map[task_idx].append(predict_task)\n",
    "print(map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}